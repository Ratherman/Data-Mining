{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1df58214",
   "metadata": {},
   "source": [
    "# Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "362741c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def argmax(lst): \n",
    "    return lst.index(max(lst))\n",
    "\n",
    "def find_max(col, DATA_COUNT):\n",
    "    max_num = -999\n",
    "    for i in range(DATA_COUNT):\n",
    "        if col[i] > max_num:\n",
    "            max_num = col[i]\n",
    "    return max_num\n",
    "\n",
    "def find_max_pos(col, DATA_COUNT):\n",
    "    max_num = -999\n",
    "    pos = -999\n",
    "    for i in range(DATA_COUNT):\n",
    "        if col[i] > max_num:\n",
    "            max_num = col[i]\n",
    "            pos = i\n",
    "    return max_num, pos\n",
    "\n",
    "def find_min(col, DATA_COUNT):\n",
    "    min_num = 100000\n",
    "    for i in range(DATA_COUNT):\n",
    "        if col[i] < min_num:\n",
    "            min_num = col[i]\n",
    "    return min_num\n",
    "\n",
    "def unique_type_count(col_array):\n",
    "    \n",
    "    toggle_0=0\n",
    "    toggle_1=0\n",
    "    toggle_2=0\n",
    "    toggle_3=0\n",
    "    toggle_4=0\n",
    "    toggle_5=0\n",
    "    toggle_6=0\n",
    "    toggle_7=0\n",
    "    toggle_8=0\n",
    "    toggle_9=0\n",
    "    \n",
    "    for i in range(len(col_array)):\n",
    "        if col_array[i] == 0: toggle_0=1\n",
    "        if col_array[i] == 1: toggle_1=1\n",
    "        if col_array[i] == 2: toggle_2=1\n",
    "        if col_array[i] == 3: toggle_3=1\n",
    "        if col_array[i] == 4: toggle_4=1\n",
    "        if col_array[i] == 5: toggle_5=1\n",
    "        if col_array[i] == 6: toggle_6=1\n",
    "        if col_array[i] == 7: toggle_7=1\n",
    "        if col_array[i] == 8: toggle_8=1\n",
    "        if col_array[i] == 9: toggle_9=1\n",
    "            \n",
    "    num_unique=toggle_0+toggle_1+toggle_2+toggle_3+toggle_4+toggle_5+toggle_6+toggle_7+toggle_8+toggle_9\n",
    "    return num_unique\n",
    "\n",
    "def sort_col(arr, DATA_COUNT):\n",
    "    \n",
    "    # 先讓 arr_sort 裡面全部都是 -100\n",
    "    arr_sort = []\n",
    "    for i in range(DATA_COUNT):\n",
    "        arr_sort.append(-100)\n",
    "        \n",
    "    for count in range(DATA_COUNT):\n",
    "\n",
    "        # 找到當前 arr 裡面的最大值 以及 他的 index\n",
    "        max_number = -1000\n",
    "        max_number_idx = -1000\n",
    "        for i in range(DATA_COUNT):\n",
    "\n",
    "            if arr[i] > max_number:\n",
    "                max_number = arr[i]\n",
    "                max_number_idx = i\n",
    "\n",
    "        # 把他便最小，這樣之後就不會挑到他了\n",
    "        arr[max_number_idx] = -1000\n",
    "\n",
    "        # 把當前最大值存到 arr_sort 裡面\n",
    "        arr_sort[count] = max_number\n",
    "    \n",
    "    return arr_sort\n",
    "\n",
    "def selective_naive_bayes(Attributes, DATA_COUNT, col_name, col_num):\n",
    "\n",
    "    Y_col = Attributes[9]\n",
    "\n",
    "    DATUM = []\n",
    "\n",
    "    for i in range(DATA_COUNT):\n",
    "\n",
    "        data = []    \n",
    "        for j in range(col_num):\n",
    "            data.append(Attributes[col_name[j]][i])\n",
    "\n",
    "        DATUM.append(data)\n",
    "\n",
    "    # 這個 loop 是在區分 testing data 和 training data 用的\n",
    "    ACC_Count = 0\n",
    "    for i in range(DATA_COUNT):\n",
    "\n",
    "        # 區分 training data 和 testing data\n",
    "        X_test = DATUM[i]\n",
    "        Y_test = Y_col[i]\n",
    "\n",
    "        X_train = []\n",
    "        Y_train = []\n",
    "        for j in range(DATA_COUNT):\n",
    "            if j != i:\n",
    "                X_train.append(DATUM[j]) # 照理來說應該只能有 213 筆\n",
    "                Y_train.append(Y_col[j]) # 照理來說應該只能有 213 筆\n",
    "\n",
    "        # 在 i-th RUN 裡面\n",
    "        # 目標是拿著 X_test 然後到 X_train 裡面算 Naive Bayes with Laplace Esitmate 的 score，然後再用 y_test 確認有無正確\n",
    "        # 有 6 種 class type: ['1\\n', '2\\n', '3\\n', '5\\n', '6\\n', '7\\n']\n",
    "\n",
    "        # (1) 計算 p(c), \n",
    "\n",
    "        count_c1 = 0\n",
    "        count_c2 = 0\n",
    "        count_c3 = 0\n",
    "        count_c5 = 0\n",
    "        count_c6 = 0\n",
    "        count_c7 = 0\n",
    "\n",
    "        for j in range(DATA_COUNT-1):\n",
    "\n",
    "            if   (Y_train[j] == \"1\\n\"): # 目的：計算 p(c=c1)，意義：Given c=c1\n",
    "                count_c1=count_c1+1\n",
    "\n",
    "            elif (Y_train[j] == \"2\\n\"): # 目的：計算 p(c=c2)，意義：Given c=c2\n",
    "                count_c2=count_c2+1\n",
    "\n",
    "            elif (Y_train[j] == \"3\\n\"): # 目的：計算 p(c=c3)，意義：Given c=c3\n",
    "                count_c3=count_c3+1\n",
    "\n",
    "            elif (Y_train[j] == \"5\\n\"): # 目的：計算 p(c=c5)，意義：Given c=c5\n",
    "                count_c5=count_c5+1\n",
    "\n",
    "            elif (Y_train[j] == \"6\\n\"): # 目的：計算 p(c=c6)，意義：Given c=c6\n",
    "                count_c6=count_c6+1\n",
    "\n",
    "            elif (Y_train[j] == \"7\\n\"): # 目的：計算 p(c=c7)，意義：Given c=c7\n",
    "                count_c7=count_c7+1\n",
    "\n",
    "        prob_c1 = count_c1/(DATA_COUNT - 1)\n",
    "        prob_c2 = count_c2/(DATA_COUNT - 1)\n",
    "        prob_c3 = count_c3/(DATA_COUNT - 1)\n",
    "        prob_c5 = count_c5/(DATA_COUNT - 1)\n",
    "        prob_c6 = count_c6/(DATA_COUNT - 1)\n",
    "        prob_c7 = count_c7/(DATA_COUNT - 1)\n",
    "\n",
    "        # (2) 計算 p(x,c)\n",
    "        cond_prob_c1=1\n",
    "        cond_prob_c2=1\n",
    "        cond_prob_c3=1\n",
    "        cond_prob_c5=1\n",
    "        cond_prob_c6=1\n",
    "        cond_prob_c7=1\n",
    "\n",
    "        for k in range(col_num):\n",
    "            target_val = X_test[k]\n",
    "            target_count_c1 = 0\n",
    "            target_count_c2 = 0\n",
    "            target_count_c3 = 0\n",
    "            target_count_c5 = 0\n",
    "            target_count_c6 = 0\n",
    "            target_count_c7 = 0\n",
    "\n",
    "            # 其實原本想要用 Attributes_EWD[Col_num]，但是後來發現我的 training dataset 是 DATA_COUNT - 1，而非 DATA_COUNT\n",
    "            # 而在檢查過後確認，有的類別確實只有一個 sample，所以才不照原本的寫法\n",
    "            target_col=[]\n",
    "            for j in range(DATA_COUNT-1):\n",
    "                target_col.append(X_train[j][k])\n",
    "\n",
    "            for j in range(DATA_COUNT-1):\n",
    "\n",
    "                if   (Y_train[j] == \"1\\n\") and (target_val == X_train[j][k]): \n",
    "                    target_count_c1=target_count_c1+1\n",
    "\n",
    "                elif (Y_train[j] == \"2\\n\") and (target_val == X_train[j][k]):\n",
    "                    target_count_c2=target_count_c2+1\n",
    "\n",
    "                elif (Y_train[j] == \"3\\n\") and (target_val == X_train[j][k]):\n",
    "                    target_count_c3=target_count_c3+1\n",
    "\n",
    "                elif (Y_train[j] == \"5\\n\") and (target_val == X_train[j][k]):\n",
    "                    target_count_c5=target_count_c5+1\n",
    "\n",
    "                elif (Y_train[j] == \"6\\n\") and (target_val == X_train[j][k]):\n",
    "                    target_count_c6=target_count_c6+1\n",
    "\n",
    "                elif (Y_train[j] == \"7\\n\") and (target_val == X_train[j][k]):\n",
    "                    target_count_c7=target_count_c7+1\n",
    "\n",
    "            # (2.5) 考慮 Laplace Estimate\n",
    "            cond_prob_c1=cond_prob_c1*(target_count_c1+1)/(count_c1+unique_type_count(target_col))\n",
    "            cond_prob_c2=cond_prob_c2*(target_count_c2+1)/(count_c2+unique_type_count(target_col))\n",
    "            cond_prob_c3=cond_prob_c3*(target_count_c3+1)/(count_c3+unique_type_count(target_col))\n",
    "            cond_prob_c5=cond_prob_c5*(target_count_c5+1)/(count_c5+unique_type_count(target_col))\n",
    "            cond_prob_c6=cond_prob_c6*(target_count_c6+1)/(count_c6+unique_type_count(target_col))\n",
    "            cond_prob_c7=cond_prob_c7*(target_count_c7+1)/(count_c7+unique_type_count(target_col))\n",
    "\n",
    "        # (3) 比較 6 個 score 看誰最高\n",
    "        score_c1=prob_c1*cond_prob_c1\n",
    "        score_c2=prob_c2*cond_prob_c2\n",
    "        score_c3=prob_c3*cond_prob_c3\n",
    "        score_c5=prob_c5*cond_prob_c5\n",
    "        score_c6=prob_c6*cond_prob_c6\n",
    "        score_c7=prob_c7*cond_prob_c7\n",
    "        score_list = [score_c1, score_c2, score_c3, score_c5, score_c6, score_c7]\n",
    "\n",
    "        # (4) 看看最高的那個類別有沒有和 y_test 一致\n",
    "        max_score, max_position = find_max_pos(score_list, 6)\n",
    "\n",
    "        if   (Y_test == '1\\n') and (max_position == 0):\n",
    "            ACC_Count = ACC_Count + 1\n",
    "        elif (Y_test == '2\\n') and (max_position == 1):\n",
    "            ACC_Count = ACC_Count + 1\n",
    "        elif (Y_test == '3\\n') and (max_position == 2):\n",
    "            ACC_Count = ACC_Count + 1\n",
    "        elif (Y_test == '5\\n') and (max_position == 3):\n",
    "            ACC_Count = ACC_Count + 1\n",
    "        elif (Y_test == '6\\n') and (max_position == 4):\n",
    "            ACC_Count = ACC_Count + 1\n",
    "        elif (Y_test == '7\\n') and (max_position == 5):\n",
    "            ACC_Count = ACC_Count + 1\n",
    "        else:\n",
    "            ACC_Count = ACC_Count\n",
    "\n",
    "    print(f\"Chosen Subset: {col_name}, Accuracy: {round(ACC_Count/DATA_COUNT*100, 3)} %\")\n",
    "    return ACC_Count / DATA_COUNT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e32690db",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73b49505",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"../glass.txt\")\n",
    "DATA = f.readlines()\n",
    "DATA_COUNT = len(DATA)\n",
    "f.close()\n",
    "\n",
    "# 觀察到 DATA 目前為 string 形式，透過 split 拆解 string，並存入 DATA_NEW\n",
    "# 另外，想要將 col 和 row 的位置對調\n",
    "\n",
    "_attr, attr_0, attr_1, attr_2, attr_3, attr_4, attr_5, attr_6, attr_7, attr_8, attr_9 = [], [], [], [], [], [], [], [], [], [], []\n",
    "\n",
    "for row in DATA:\n",
    "\n",
    "    row_list = row.split(\",\")\n",
    "    \n",
    "    attr_0.append(float(row_list[1]))   \n",
    "    attr_1.append(float(row_list[2]))  \n",
    "    attr_2.append(float(row_list[3]))  \n",
    "    attr_3.append(float(row_list[4]))\n",
    "    attr_4.append(float(row_list[5]))\n",
    "    attr_5.append(float(row_list[6]))  \n",
    "    attr_6.append(float(row_list[7]))  \n",
    "    attr_7.append(float(row_list[8]))\n",
    "    attr_8.append(float(row_list[9]))\n",
    "    attr_9.append(row_list[10]) # 這個是 class\n",
    "    \n",
    "\n",
    "# 我只要透過 Attributes[0] 就能取得 DATA 第一個 Attribute 的所有值（預計有214個）\n",
    "Attributes = [attr_0, attr_1, attr_2, attr_3, attr_4, attr_5, attr_6, attr_7, attr_8, attr_9]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b473b39",
   "metadata": {},
   "source": [
    "# Equal-Width Discretization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "082c6aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "Attributes_EWD = []\n",
    "for i in range(10):\n",
    "    \n",
    "    specific_col = Attributes[i]\n",
    "    \n",
    "    if i != 9:\n",
    "        number_of_intervals = 10\n",
    "        max_num_in_col = find_max(specific_col, DATA_COUNT)\n",
    "        min_num_in_col = find_min(specific_col, DATA_COUNT)\n",
    "        width = (max_num_in_col - min_num_in_col)/number_of_intervals\n",
    "\n",
    "        # Decide 9 Split points, so that 10 intervals will form\n",
    "        split_point_1 = max_num_in_col - 1 * width\n",
    "        split_point_2 = max_num_in_col - 2 * width\n",
    "        split_point_3 = max_num_in_col - 3 * width\n",
    "        split_point_4 = max_num_in_col - 4 * width\n",
    "        split_point_5 = max_num_in_col - 5 * width\n",
    "        split_point_6 = max_num_in_col - 6 * width\n",
    "        split_point_7 = max_num_in_col - 7 * width\n",
    "        split_point_8 = max_num_in_col - 8 * width\n",
    "        split_point_9 = max_num_in_col - 9 * width\n",
    "\n",
    "        # transfer attributes into proper interval\n",
    "        discrete_attr = []\n",
    "        for i in range(DATA_COUNT):\n",
    "            discrete_attr.append(-100)\n",
    "\n",
    "        for i in range(DATA_COUNT):\n",
    "\n",
    "            num = specific_col[i]\n",
    "\n",
    "            if (num >= split_point_1): discrete_attr[i] = 0\n",
    "            elif (num >= split_point_2) and (num < split_point_1): discrete_attr[i] = 1\n",
    "            elif (num >= split_point_3) and (num < split_point_2): discrete_attr[i] = 2\n",
    "            elif (num >= split_point_4) and (num < split_point_3): discrete_attr[i] = 3\n",
    "            elif (num >= split_point_5) and (num < split_point_4): discrete_attr[i] = 4\n",
    "            elif (num >= split_point_6) and (num < split_point_5): discrete_attr[i] = 5\n",
    "            elif (num >= split_point_7) and (num < split_point_6): discrete_attr[i] = 6\n",
    "            elif (num >= split_point_8) and (num < split_point_7): discrete_attr[i] = 7\n",
    "            elif (num >= split_point_9) and (num < split_point_8): discrete_attr[i] = 8\n",
    "            elif (num  < split_point_9): discrete_attr[i] = 9\n",
    "                \n",
    "        Attributes_EWD.append(discrete_attr)\n",
    "    else:\n",
    "        Attributes_EWD.append(specific_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7fb723b",
   "metadata": {},
   "source": [
    "# Use Selective Naïve Bayes (w. Laplace estimate) to Forward Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a9b91bfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chosen Subset: [0], Accuracy: 39.72 %\n",
      "Chosen Subset: [1], Accuracy: 40.654 %\n",
      "Chosen Subset: [2], Accuracy: 44.86 %\n",
      "Chosen Subset: [3], Accuracy: 50.467 %\n",
      "Chosen Subset: [4], Accuracy: 35.047 %\n",
      "Chosen Subset: [5], Accuracy: 44.393 %\n",
      "Chosen Subset: [6], Accuracy: 48.598 %\n",
      "Chosen Subset: [7], Accuracy: 46.729 %\n",
      "Chosen Subset: [8], Accuracy: 33.645 %\n",
      "Chosen Subset: [3, 0], Accuracy: 47.196 %\n",
      "Chosen Subset: [3, 1], Accuracy: 51.402 %\n",
      "Chosen Subset: [3, 2], Accuracy: 38.785 %\n",
      "Chosen Subset: [3, 4], Accuracy: 42.991 %\n",
      "Chosen Subset: [3, 5], Accuracy: 53.738 %\n",
      "Chosen Subset: [3, 6], Accuracy: 47.196 %\n",
      "Chosen Subset: [3, 7], Accuracy: 53.271 %\n",
      "Chosen Subset: [3, 8], Accuracy: 48.131 %\n",
      "Chosen Subset: [3, 5, 0], Accuracy: 53.271 %\n",
      "Chosen Subset: [3, 5, 1], Accuracy: 53.271 %\n",
      "Chosen Subset: [3, 5, 2], Accuracy: 54.206 %\n",
      "Chosen Subset: [3, 5, 4], Accuracy: 56.075 %\n",
      "Chosen Subset: [3, 5, 6], Accuracy: 52.336 %\n",
      "Chosen Subset: [3, 5, 7], Accuracy: 55.607 %\n",
      "Chosen Subset: [3, 5, 8], Accuracy: 52.336 %\n",
      "Chosen Subset: [3, 5, 4, 0], Accuracy: 54.673 %\n",
      "Chosen Subset: [3, 5, 4, 1], Accuracy: 57.009 %\n",
      "Chosen Subset: [3, 5, 4, 2], Accuracy: 55.14 %\n",
      "Chosen Subset: [3, 5, 4, 6], Accuracy: 51.869 %\n",
      "Chosen Subset: [3, 5, 4, 7], Accuracy: 57.944 %\n",
      "Chosen Subset: [3, 5, 4, 8], Accuracy: 54.206 %\n",
      "Chosen Subset: [3, 5, 4, 7, 0], Accuracy: 57.477 %\n",
      "Chosen Subset: [3, 5, 4, 7, 1], Accuracy: 57.477 %\n",
      "Chosen Subset: [3, 5, 4, 7, 2], Accuracy: 57.944 %\n",
      "Chosen Subset: [3, 5, 4, 7, 6], Accuracy: 54.673 %\n",
      "Chosen Subset: [3, 5, 4, 7, 8], Accuracy: 56.075 %\n",
      "Chosen Subset: [3, 5, 4, 7, 2, 0], Accuracy: 57.477 %\n",
      "Chosen Subset: [3, 5, 4, 7, 2, 1], Accuracy: 55.607 %\n",
      "Chosen Subset: [3, 5, 4, 7, 2, 6], Accuracy: 62.617 %\n",
      "Chosen Subset: [3, 5, 4, 7, 2, 8], Accuracy: 59.813 %\n",
      "Chosen Subset: [3, 5, 4, 7, 2, 6, 0], Accuracy: 59.813 %\n",
      "Chosen Subset: [3, 5, 4, 7, 2, 6, 1], Accuracy: 59.813 %\n",
      "Chosen Subset: [3, 5, 4, 7, 2, 6, 8], Accuracy: 62.15 %\n",
      "\n",
      "Finish. The best setting based on Selective Naive Bayes (with Laplace Estimate) is ...\n",
      "Chosen Subset: [3, 5, 4, 7, 2, 6], Accuracy: 62.617 %\n"
     ]
    }
   ],
   "source": [
    "must_chosen_subset = []\n",
    "possible_subset = [0,1,2,3,4,5,6,7,8]\n",
    "best_accuracy = 0\n",
    "\n",
    "while True:\n",
    "    \n",
    "    # 一個 accuracy 會對應到 一個 experiment 的 col\n",
    "    accuracy_list = []\n",
    "    exp_attr_list = []\n",
    "\n",
    "    # 進行同樣 attr 數目的搜索\n",
    "    for attr_num in possible_subset:\n",
    "\n",
    "        # 每次搜索過相同 level 的 subset 時，需要清空 chosen_subset\n",
    "        chosen_subset = [] # zero_subset 的概念\n",
    "\n",
    "        # 把那些 最棒的 attr 加進來\n",
    "        for best_attr_num in must_chosen_subset:\n",
    "            chosen_subset.append(best_attr_num)\n",
    "\n",
    "        # 這時候從 possible_subset 加一個候選的 attr 進到 chosen_subset\n",
    "        chosen_subset.append(attr_num)\n",
    "        exp_attr_list.append(attr_num)\n",
    "\n",
    "        # 計算 accuracy 並且將 accuracy 放入 accuracy_list\n",
    "        accuracy = selective_naive_bayes(Attributes_EWD, DATA_COUNT, chosen_subset, len(chosen_subset))\n",
    "        accuracy_list.append(accuracy)\n",
    "        #print(f\"Chosen S: {chosen_subset}; Goodness: {round(accuracy,3)}\")\n",
    "\n",
    "    # 找到 goodness 最大的 idx, 並透過 tmp_exp_col 找到 attr_num 和 goodness\n",
    "    idx = argmax(accuracy_list)\n",
    "    current_best_atrr = exp_attr_list[idx]\n",
    "    current_best_accuracy = accuracy_list[idx]\n",
    "\n",
    "    # 設定停止條件 \n",
    "    # (1) current_best_goodness 比 best_goodness 低 \n",
    "    # (2) possible_subset 用完了\n",
    "    if (current_best_accuracy < best_accuracy) or (len(possible_subset) < 2):\n",
    "        break;\n",
    "    else:\n",
    "        # 把當前最好的 attr 加進 must_chosen_subset 裡面\n",
    "        must_chosen_subset.append(current_best_atrr)\n",
    "        # 把當前最好的 attr 從 possible_subset 裡面取出\n",
    "        possible_subset.remove(current_best_atrr)\n",
    "        # 更新歷史上最好的 best_goodness\n",
    "        best_accuracy = current_best_accuracy\n",
    "\n",
    "print()\n",
    "print(f\"Finish. The best setting based on Selective Naive Bayes (with Laplace Estimate) is ...\")\n",
    "_ = selective_naive_bayes(Attributes_EWD, DATA_COUNT, must_chosen_subset, len(must_chosen_subset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e324a1",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "282f1497",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"../glass.txt\")\n",
    "DATA = f.readlines()\n",
    "DATA_COUNT = len(DATA)\n",
    "f.close()\n",
    "\n",
    "# 觀察到 DATA 目前為 string 形式，透過 split 拆解 string，並存入 DATA_NEW\n",
    "# 另外，想要將 col 和 row 的位置對調\n",
    "\n",
    "_attr, attr_0, attr_1, attr_2, attr_3, attr_4, attr_5, attr_6, attr_7, attr_8, attr_9 = [], [], [], [], [], [], [], [], [], [], []\n",
    "\n",
    "for row in DATA:\n",
    "\n",
    "    row_list = row.split(\",\")\n",
    "    \n",
    "    attr_0.append(float(row_list[1]))   \n",
    "    attr_1.append(float(row_list[2]))  \n",
    "    attr_2.append(float(row_list[3]))  \n",
    "    attr_3.append(float(row_list[4]))\n",
    "    attr_4.append(float(row_list[5]))\n",
    "    attr_5.append(float(row_list[6]))  \n",
    "    attr_6.append(float(row_list[7]))  \n",
    "    attr_7.append(float(row_list[8]))\n",
    "    attr_8.append(float(row_list[9]))\n",
    "    attr_9.append(row_list[10]) # 這個是 class\n",
    "    \n",
    "\n",
    "# 我只要透過 Attributes[0] 就能取得 DATA 第一個 Attribute 的所有值（預計有214個）\n",
    "Attributes = [attr_0, attr_1, attr_2, attr_3, attr_4, attr_5, attr_6, attr_7, attr_8, attr_9]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0933ee",
   "metadata": {},
   "source": [
    "# Equal-Frequency Discretization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "88c27a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "Attributes_Sort = []\n",
    "\n",
    "for i in range(10):\n",
    "    if i < 9:\n",
    "        Attributes_Sort.append(sort_col(Attributes[i], DATA_COUNT))\n",
    "    else:\n",
    "        Attributes_Sort.append(Attributes[i])\n",
    "# 我只要透過 Attributes_Sort[0] 就能取得 DATA 第一個 Attribute 的所有值（預計有106個），而且還有由大排到小"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7126db83",
   "metadata": {},
   "source": [
    "# Read Data Again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b9de3ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"../glass.txt\")\n",
    "DATA = f.readlines()\n",
    "DATA_COUNT = len(DATA)\n",
    "f.close()\n",
    "\n",
    "number_of_intervals = 10\n",
    "number_of_attr_in_interval = DATA_COUNT / number_of_intervals\n",
    "\n",
    "# 觀察到 DATA 目前為 string 形式，透過 split 拆解 string，並存入 DATA_NEW\n",
    "# 另外，想要將 col 和 row 的位置對調\n",
    "\n",
    "_attr, attr_0, attr_1, attr_2, attr_3, attr_4, attr_5, attr_6, attr_7, attr_8, attr_9 = [], [], [], [], [], [], [], [], [], [], []\n",
    "\n",
    "for row in DATA:\n",
    "\n",
    "    row_list = row.split(\",\")\n",
    "    \n",
    "    attr_0.append(float(row_list[1]))   \n",
    "    attr_1.append(float(row_list[2]))  \n",
    "    attr_2.append(float(row_list[3]))  \n",
    "    attr_3.append(float(row_list[4]))\n",
    "    attr_4.append(float(row_list[5]))\n",
    "    attr_5.append(float(row_list[6]))  \n",
    "    attr_6.append(float(row_list[7]))  \n",
    "    attr_7.append(float(row_list[8]))\n",
    "    attr_8.append(float(row_list[9]))\n",
    "    attr_9.append(row_list[10]) # 這個是 class\n",
    "    \n",
    "\n",
    "# 我只要透過 Attributes[0] 就能取得 DATA 第一個 Attribute 的所有值（預計有214個）\n",
    "Attributes = [attr_0, attr_1, attr_2, attr_3, attr_4, attr_5, attr_6, attr_7, attr_8, attr_9]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230d5858",
   "metadata": {},
   "source": [
    "# Equal-Frequency Discretization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "47a5fdbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "Attributes_EFD = []\n",
    "\n",
    "for j in range(10):\n",
    "    specific_col_sort = Attributes_Sort[j]\n",
    "    specific_col = Attributes[j]\n",
    "    \n",
    "    if j != 9:\n",
    "\n",
    "        split_point_1 = specific_col_sort[1 * int(number_of_attr_in_interval)]\n",
    "        split_point_2 = specific_col_sort[2 * int(number_of_attr_in_interval)]\n",
    "        split_point_3 = specific_col_sort[3 * int(number_of_attr_in_interval)]\n",
    "        split_point_4 = specific_col_sort[4 * int(number_of_attr_in_interval)]\n",
    "        split_point_5 = specific_col_sort[5 * int(number_of_attr_in_interval)]\n",
    "        split_point_6 = specific_col_sort[6 * int(number_of_attr_in_interval)]\n",
    "        split_point_7 = specific_col_sort[7 * int(number_of_attr_in_interval)]\n",
    "        split_point_8 = specific_col_sort[8 * int(number_of_attr_in_interval)]\n",
    "        split_point_9 = specific_col_sort[9 * int(number_of_attr_in_interval)]\n",
    "\n",
    "        # transfer attributes into proper interval\n",
    "        discrete_attr = []\n",
    "        for i in range(DATA_COUNT):\n",
    "            discrete_attr.append(-100)\n",
    "\n",
    "        for i in range(DATA_COUNT):\n",
    "\n",
    "            num = specific_col[i]\n",
    "\n",
    "            if num >= split_point_1: discrete_attr[i] = 0\n",
    "            elif num >= split_point_2 and num < split_point_1: discrete_attr[i] = 1\n",
    "            elif num >= split_point_3 and num < split_point_2: discrete_attr[i] = 2\n",
    "            elif num >= split_point_4 and num < split_point_3: discrete_attr[i] = 3\n",
    "            elif num >= split_point_5 and num < split_point_4: discrete_attr[i] = 4\n",
    "            elif num >= split_point_6 and num < split_point_5: discrete_attr[i] = 5\n",
    "            elif num >= split_point_7 and num < split_point_6: discrete_attr[i] = 6\n",
    "            elif num >= split_point_8 and num < split_point_7: discrete_attr[i] = 7\n",
    "            elif num >= split_point_9 and num < split_point_8: discrete_attr[i] = 8\n",
    "            elif num < split_point_9: discrete_attr[i] = 9\n",
    "                \n",
    "        Attributes_EFD.append(discrete_attr)\n",
    "    else:\n",
    "        Attributes_EFD.append(specific_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9414b14",
   "metadata": {},
   "source": [
    "# Use Selective Naïve Bayes (w. Laplace estimate) to Forward Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "239faa4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chosen Subset: [0], Accuracy: 52.804 %\n",
      "Chosen Subset: [1], Accuracy: 45.327 %\n",
      "Chosen Subset: [2], Accuracy: 38.318 %\n",
      "Chosen Subset: [3], Accuracy: 57.944 %\n",
      "Chosen Subset: [4], Accuracy: 43.458 %\n",
      "Chosen Subset: [5], Accuracy: 43.458 %\n",
      "Chosen Subset: [6], Accuracy: 49.065 %\n",
      "Chosen Subset: [7], Accuracy: 44.393 %\n",
      "Chosen Subset: [8], Accuracy: 36.916 %\n",
      "Chosen Subset: [3, 0], Accuracy: 58.879 %\n",
      "Chosen Subset: [3, 1], Accuracy: 55.14 %\n",
      "Chosen Subset: [3, 2], Accuracy: 57.944 %\n",
      "Chosen Subset: [3, 4], Accuracy: 54.673 %\n",
      "Chosen Subset: [3, 5], Accuracy: 52.336 %\n",
      "Chosen Subset: [3, 6], Accuracy: 57.477 %\n",
      "Chosen Subset: [3, 7], Accuracy: 57.009 %\n",
      "Chosen Subset: [3, 8], Accuracy: 57.009 %\n",
      "Chosen Subset: [3, 0, 1], Accuracy: 60.28 %\n",
      "Chosen Subset: [3, 0, 2], Accuracy: 62.617 %\n",
      "Chosen Subset: [3, 0, 4], Accuracy: 57.944 %\n",
      "Chosen Subset: [3, 0, 5], Accuracy: 60.748 %\n",
      "Chosen Subset: [3, 0, 6], Accuracy: 62.617 %\n",
      "Chosen Subset: [3, 0, 7], Accuracy: 60.748 %\n",
      "Chosen Subset: [3, 0, 8], Accuracy: 61.215 %\n",
      "Chosen Subset: [3, 0, 2, 1], Accuracy: 67.29 %\n",
      "Chosen Subset: [3, 0, 2, 4], Accuracy: 62.617 %\n",
      "Chosen Subset: [3, 0, 2, 5], Accuracy: 64.953 %\n",
      "Chosen Subset: [3, 0, 2, 6], Accuracy: 65.888 %\n",
      "Chosen Subset: [3, 0, 2, 7], Accuracy: 65.888 %\n",
      "Chosen Subset: [3, 0, 2, 8], Accuracy: 64.953 %\n",
      "Chosen Subset: [3, 0, 2, 1, 4], Accuracy: 64.486 %\n",
      "Chosen Subset: [3, 0, 2, 1, 5], Accuracy: 63.084 %\n",
      "Chosen Subset: [3, 0, 2, 1, 6], Accuracy: 67.29 %\n",
      "Chosen Subset: [3, 0, 2, 1, 7], Accuracy: 69.626 %\n",
      "Chosen Subset: [3, 0, 2, 1, 8], Accuracy: 65.888 %\n",
      "Chosen Subset: [3, 0, 2, 1, 7, 4], Accuracy: 67.29 %\n",
      "Chosen Subset: [3, 0, 2, 1, 7, 5], Accuracy: 67.29 %\n",
      "Chosen Subset: [3, 0, 2, 1, 7, 6], Accuracy: 68.692 %\n",
      "Chosen Subset: [3, 0, 2, 1, 7, 8], Accuracy: 68.692 %\n",
      "\n",
      "Finish. The best setting based on Selective Naive Bayes (with Laplace Estimate) is ...\n",
      "Chosen Subset: [3, 0, 2, 1, 7], Accuracy: 69.626 %\n"
     ]
    }
   ],
   "source": [
    "must_chosen_subset = []\n",
    "possible_subset = [0,1,2,3,4,5,6,7,8]\n",
    "best_accuracy = 0\n",
    "\n",
    "while True:\n",
    "    \n",
    "    # 一個 accuracy 會對應到 一個 experiment 的 col\n",
    "    accuracy_list = []\n",
    "    exp_attr_list = []\n",
    "\n",
    "    # 進行同樣 attr 數目的搜索\n",
    "    for attr_num in possible_subset:\n",
    "\n",
    "        # 每次搜索過相同 level 的 subset 時，需要清空 chosen_subset\n",
    "        chosen_subset = [] # zero_subset 的概念\n",
    "\n",
    "        # 把那些 最棒的 attr 加進來\n",
    "        for best_attr_num in must_chosen_subset:\n",
    "            chosen_subset.append(best_attr_num)\n",
    "\n",
    "        # 這時候從 possible_subset 加一個候選的 attr 進到 chosen_subset\n",
    "        chosen_subset.append(attr_num)\n",
    "        exp_attr_list.append(attr_num)\n",
    "\n",
    "        # 計算 accuracy 並且將 accuracy 放入 accuracy_list\n",
    "        accuracy = selective_naive_bayes(Attributes_EFD, DATA_COUNT, chosen_subset, len(chosen_subset))\n",
    "        accuracy_list.append(accuracy)\n",
    "        #print(f\"Chosen S: {chosen_subset}; Goodness: {round(accuracy,3)}\")\n",
    "\n",
    "    # 找到 goodness 最大的 idx, 並透過 tmp_exp_col 找到 attr_num 和 goodness\n",
    "    idx = argmax(accuracy_list)\n",
    "    current_best_atrr = exp_attr_list[idx]\n",
    "    current_best_accuracy = accuracy_list[idx]\n",
    "\n",
    "    # 設定停止條件 \n",
    "    # (1) current_best_goodness 比 best_goodness 低 \n",
    "    # (2) possible_subset 用完了\n",
    "    if (current_best_accuracy < best_accuracy) or (len(possible_subset) < 2):\n",
    "        break;\n",
    "    else:\n",
    "        # 把當前最好的 attr 加進 must_chosen_subset 裡面\n",
    "        must_chosen_subset.append(current_best_atrr)\n",
    "        # 把當前最好的 attr 從 possible_subset 裡面取出\n",
    "        possible_subset.remove(current_best_atrr)\n",
    "        # 更新歷史上最好的 best_goodness\n",
    "        best_accuracy = current_best_accuracy\n",
    "\n",
    "print()\n",
    "print(f\"Finish. The best setting based on Selective Naive Bayes (with Laplace Estimate) is ...\")\n",
    "_ = selective_naive_bayes(Attributes_EFD, DATA_COUNT, must_chosen_subset, len(must_chosen_subset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b87f750b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entropy-based Discretization"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
