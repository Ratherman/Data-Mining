{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1df58214",
   "metadata": {},
   "source": [
    "# Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "362741c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def argmax(lst): \n",
    "    return lst.index(max(lst))\n",
    "\n",
    "def find_max(col, DATA_COUNT):\n",
    "    max_num = -999\n",
    "    for i in range(DATA_COUNT):\n",
    "        if col[i] > max_num:\n",
    "            max_num = col[i]\n",
    "    return max_num\n",
    "\n",
    "def find_max_pos(col, DATA_COUNT):\n",
    "    max_num = -999\n",
    "    pos = -999\n",
    "    for i in range(DATA_COUNT):\n",
    "        if col[i] > max_num:\n",
    "            max_num = col[i]\n",
    "            pos = i\n",
    "    return max_num, pos\n",
    "\n",
    "def find_min(col, DATA_COUNT):\n",
    "    min_num = 100000\n",
    "    for i in range(DATA_COUNT):\n",
    "        if col[i] < min_num:\n",
    "            min_num = col[i]\n",
    "    return min_num\n",
    "\n",
    "def unique_type_count(col_array):\n",
    "    \n",
    "    toggle_0=0\n",
    "    toggle_1=0\n",
    "    toggle_2=0\n",
    "    toggle_3=0\n",
    "    toggle_4=0\n",
    "    toggle_5=0\n",
    "    toggle_6=0\n",
    "    toggle_7=0\n",
    "    toggle_8=0\n",
    "    toggle_9=0\n",
    "    \n",
    "    for i in range(len(col_array)):\n",
    "        if col_array[i] == 0: toggle_0=1\n",
    "        if col_array[i] == 1: toggle_1=1\n",
    "        if col_array[i] == 2: toggle_2=1\n",
    "        if col_array[i] == 3: toggle_3=1\n",
    "        if col_array[i] == 4: toggle_4=1\n",
    "        if col_array[i] == 5: toggle_5=1\n",
    "        if col_array[i] == 6: toggle_6=1\n",
    "        if col_array[i] == 7: toggle_7=1\n",
    "        if col_array[i] == 8: toggle_8=1\n",
    "        if col_array[i] == 9: toggle_9=1\n",
    "            \n",
    "    num_unique=toggle_0+toggle_1+toggle_2+toggle_3+toggle_4+toggle_5+toggle_6+toggle_7+toggle_8+toggle_9\n",
    "    return num_unique\n",
    "\n",
    "def sort_col(arr, DATA_COUNT):\n",
    "    \n",
    "    # 先讓 arr_sort 裡面全部都是 -100\n",
    "    arr_sort = []\n",
    "    for i in range(DATA_COUNT):\n",
    "        arr_sort.append(-100)\n",
    "        \n",
    "    for count in range(DATA_COUNT):\n",
    "\n",
    "        # 找到當前 arr 裡面的最大值 以及 他的 index\n",
    "        max_number = -1000\n",
    "        max_number_idx = -1000\n",
    "        for i in range(DATA_COUNT):\n",
    "\n",
    "            if arr[i] > max_number:\n",
    "                max_number = arr[i]\n",
    "                max_number_idx = i\n",
    "\n",
    "        # 把他便最小，這樣之後就不會挑到他了\n",
    "        arr[max_number_idx] = -1000\n",
    "\n",
    "        # 把當前最大值存到 arr_sort 裡面\n",
    "        arr_sort[count] = max_number\n",
    "    \n",
    "    return arr_sort\n",
    "\n",
    "def selective_naive_bayes(Attributes, DATA_COUNT, col_name, col_num):\n",
    "\n",
    "    Y_col = Attributes[9]\n",
    "\n",
    "    DATUM = []\n",
    "\n",
    "    for i in range(DATA_COUNT):\n",
    "\n",
    "        data = []    \n",
    "        for j in range(col_num):\n",
    "            data.append(Attributes[col_name[j]][i])\n",
    "\n",
    "        DATUM.append(data)\n",
    "\n",
    "    # 這個 loop 是在區分 testing data 和 training data 用的\n",
    "    ACC_Count = 0\n",
    "    for i in range(DATA_COUNT):\n",
    "\n",
    "        # 區分 training data 和 testing data\n",
    "        X_test = DATUM[i]\n",
    "        Y_test = Y_col[i]\n",
    "\n",
    "        X_train = []\n",
    "        Y_train = []\n",
    "        for j in range(DATA_COUNT):\n",
    "            if j != i:\n",
    "                X_train.append(DATUM[j]) # 照理來說應該只能有 213 筆\n",
    "                Y_train.append(Y_col[j]) # 照理來說應該只能有 213 筆\n",
    "\n",
    "        # 在 i-th RUN 裡面\n",
    "        # 目標是拿著 X_test 然後到 X_train 裡面算 Naive Bayes with Laplace Esitmate 的 score，然後再用 y_test 確認有無正確\n",
    "        # 有 6 種 class type: ['1\\n', '2\\n', '3\\n', '5\\n', '6\\n', '7\\n']\n",
    "\n",
    "        # (1) 計算 p(c), \n",
    "\n",
    "        count_c1 = 0\n",
    "        count_c2 = 0\n",
    "        count_c3 = 0\n",
    "        count_c5 = 0\n",
    "        count_c6 = 0\n",
    "        count_c7 = 0\n",
    "\n",
    "        for j in range(DATA_COUNT-1):\n",
    "\n",
    "            if   (Y_train[j] == \"1\\n\"): # 目的：計算 p(c=c1)，意義：Given c=c1\n",
    "                count_c1=count_c1+1\n",
    "\n",
    "            elif (Y_train[j] == \"2\\n\"): # 目的：計算 p(c=c2)，意義：Given c=c2\n",
    "                count_c2=count_c2+1\n",
    "\n",
    "            elif (Y_train[j] == \"3\\n\"): # 目的：計算 p(c=c3)，意義：Given c=c3\n",
    "                count_c3=count_c3+1\n",
    "\n",
    "            elif (Y_train[j] == \"5\\n\"): # 目的：計算 p(c=c5)，意義：Given c=c5\n",
    "                count_c5=count_c5+1\n",
    "\n",
    "            elif (Y_train[j] == \"6\\n\"): # 目的：計算 p(c=c6)，意義：Given c=c6\n",
    "                count_c6=count_c6+1\n",
    "\n",
    "            elif (Y_train[j] == \"7\\n\"): # 目的：計算 p(c=c7)，意義：Given c=c7\n",
    "                count_c7=count_c7+1\n",
    "\n",
    "        prob_c1 = count_c1/(DATA_COUNT - 1)\n",
    "        prob_c2 = count_c2/(DATA_COUNT - 1)\n",
    "        prob_c3 = count_c3/(DATA_COUNT - 1)\n",
    "        prob_c5 = count_c5/(DATA_COUNT - 1)\n",
    "        prob_c6 = count_c6/(DATA_COUNT - 1)\n",
    "        prob_c7 = count_c7/(DATA_COUNT - 1)\n",
    "\n",
    "        # (2) 計算 p(x,c)\n",
    "        cond_prob_c1=1\n",
    "        cond_prob_c2=1\n",
    "        cond_prob_c3=1\n",
    "        cond_prob_c5=1\n",
    "        cond_prob_c6=1\n",
    "        cond_prob_c7=1\n",
    "\n",
    "        for k in range(col_num):\n",
    "            target_val = X_test[k]\n",
    "            target_count_c1 = 0\n",
    "            target_count_c2 = 0\n",
    "            target_count_c3 = 0\n",
    "            target_count_c5 = 0\n",
    "            target_count_c6 = 0\n",
    "            target_count_c7 = 0\n",
    "\n",
    "            # 其實原本想要用 Attributes_EWD[Col_num]，但是後來發現我的 training dataset 是 DATA_COUNT - 1，而非 DATA_COUNT\n",
    "            # 而在檢查過後確認，有的類別確實只有一個 sample，所以才不照原本的寫法\n",
    "            target_col=[]\n",
    "            for j in range(DATA_COUNT-1):\n",
    "                target_col.append(X_train[j][k])\n",
    "\n",
    "            for j in range(DATA_COUNT-1):\n",
    "\n",
    "                if   (Y_train[j] == \"1\\n\") and (target_val == X_train[j][k]): \n",
    "                    target_count_c1=target_count_c1+1\n",
    "\n",
    "                elif (Y_train[j] == \"2\\n\") and (target_val == X_train[j][k]):\n",
    "                    target_count_c2=target_count_c2+1\n",
    "\n",
    "                elif (Y_train[j] == \"3\\n\") and (target_val == X_train[j][k]):\n",
    "                    target_count_c3=target_count_c3+1\n",
    "\n",
    "                elif (Y_train[j] == \"5\\n\") and (target_val == X_train[j][k]):\n",
    "                    target_count_c5=target_count_c5+1\n",
    "\n",
    "                elif (Y_train[j] == \"6\\n\") and (target_val == X_train[j][k]):\n",
    "                    target_count_c6=target_count_c6+1\n",
    "\n",
    "                elif (Y_train[j] == \"7\\n\") and (target_val == X_train[j][k]):\n",
    "                    target_count_c7=target_count_c7+1\n",
    "\n",
    "            # (2.5) 考慮 Laplace Estimate\n",
    "            cond_prob_c1=cond_prob_c1*(target_count_c1+1)/(count_c1+unique_type_count(target_col))\n",
    "            cond_prob_c2=cond_prob_c2*(target_count_c2+1)/(count_c2+unique_type_count(target_col))\n",
    "            cond_prob_c3=cond_prob_c3*(target_count_c3+1)/(count_c3+unique_type_count(target_col))\n",
    "            cond_prob_c5=cond_prob_c5*(target_count_c5+1)/(count_c5+unique_type_count(target_col))\n",
    "            cond_prob_c6=cond_prob_c6*(target_count_c6+1)/(count_c6+unique_type_count(target_col))\n",
    "            cond_prob_c7=cond_prob_c7*(target_count_c7+1)/(count_c7+unique_type_count(target_col))\n",
    "\n",
    "        # (3) 比較 6 個 score 看誰最高\n",
    "        score_c1=prob_c1*cond_prob_c1\n",
    "        score_c2=prob_c2*cond_prob_c2\n",
    "        score_c3=prob_c3*cond_prob_c3\n",
    "        score_c5=prob_c5*cond_prob_c5\n",
    "        score_c6=prob_c6*cond_prob_c6\n",
    "        score_c7=prob_c7*cond_prob_c7\n",
    "        score_list = [score_c1, score_c2, score_c3, score_c5, score_c6, score_c7]\n",
    "        \n",
    "        #print(\"score\", score_list)\n",
    "        #print(prob_c1)\n",
    "        print(cond_prob_c2)\n",
    "        # (4) 看看最高的那個類別有沒有和 y_test 一致\n",
    "        max_score, max_position = find_max_pos(score_list, 6)\n",
    "\n",
    "        if   (Y_test == '1\\n') and (max_position == 0):\n",
    "            ACC_Count = ACC_Count + 1\n",
    "        elif (Y_test == '2\\n') and (max_position == 1):\n",
    "            ACC_Count = ACC_Count + 1\n",
    "        elif (Y_test == '3\\n') and (max_position == 2):\n",
    "            ACC_Count = ACC_Count + 1\n",
    "        elif (Y_test == '5\\n') and (max_position == 3):\n",
    "            ACC_Count = ACC_Count + 1\n",
    "        elif (Y_test == '6\\n') and (max_position == 4):\n",
    "            ACC_Count = ACC_Count + 1\n",
    "        elif (Y_test == '7\\n') and (max_position == 5):\n",
    "            ACC_Count = ACC_Count + 1\n",
    "        else:\n",
    "            ACC_Count = ACC_Count\n",
    "\n",
    "    print(f\"Chosen Subset: {col_name}, Accuracy: {round(ACC_Count/DATA_COUNT*100, 3)} %\")\n",
    "    return ACC_Count / DATA_COUNT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e32690db",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73b49505",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"../glass.txt\")\n",
    "DATA = f.readlines()\n",
    "DATA_COUNT = len(DATA)\n",
    "f.close()\n",
    "\n",
    "# 觀察到 DATA 目前為 string 形式，透過 split 拆解 string，並存入 DATA_NEW\n",
    "# 另外，想要將 col 和 row 的位置對調\n",
    "\n",
    "_attr, attr_0, attr_1, attr_2, attr_3, attr_4, attr_5, attr_6, attr_7, attr_8, attr_9 = [], [], [], [], [], [], [], [], [], [], []\n",
    "\n",
    "for row in DATA:\n",
    "\n",
    "    row_list = row.split(\",\")\n",
    "    \n",
    "    attr_0.append(float(row_list[1]))   \n",
    "    attr_1.append(float(row_list[2]))  \n",
    "    attr_2.append(float(row_list[3]))  \n",
    "    attr_3.append(float(row_list[4]))\n",
    "    attr_4.append(float(row_list[5]))\n",
    "    attr_5.append(float(row_list[6]))  \n",
    "    attr_6.append(float(row_list[7]))  \n",
    "    attr_7.append(float(row_list[8]))\n",
    "    attr_8.append(float(row_list[9]))\n",
    "    attr_9.append(row_list[10]) # 這個是 class\n",
    "    \n",
    "\n",
    "# 我只要透過 Attributes[0] 就能取得 DATA 第一個 Attribute 的所有值（預計有214個）\n",
    "Attributes = [attr_0, attr_1, attr_2, attr_3, attr_4, attr_5, attr_6, attr_7, attr_8, attr_9]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b473b39",
   "metadata": {},
   "source": [
    "# Equal-Width Discretization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "082c6aaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.53393 1.51115\n",
      "\n",
      "第 0 個 Attribute\n",
      "第一區間 [1.532 ~ max_num]\n",
      "第二區間 [1.529 ~ 1.532)\n",
      "第三區間 [1.527 ~ 1.529)\n",
      "第四區間 [1.525 ~ 1.527)\n",
      "第五區間 [1.523 ~ 1.525)\n",
      "第六區間 [1.52 ~ 1.523)\n",
      "第七區間 [1.518 ~ 1.52)\n",
      "第八區間 [1.516 ~ 1.518)\n",
      "第九區間 [1.513 ~ 1.516)\n",
      "第十區間 [min_num ~ 1.513)\n",
      "17.38 10.73\n",
      "\n",
      "第 1 個 Attribute\n",
      "第一區間 [16.715 ~ max_num]\n",
      "第二區間 [16.05 ~ 16.715)\n",
      "第三區間 [15.385 ~ 16.05)\n",
      "第四區間 [14.72 ~ 15.385)\n",
      "第五區間 [14.055 ~ 14.72)\n",
      "第六區間 [13.39 ~ 14.055)\n",
      "第七區間 [12.725 ~ 13.39)\n",
      "第八區間 [12.06 ~ 12.725)\n",
      "第九區間 [11.395 ~ 12.06)\n",
      "第十區間 [min_num ~ 11.395)\n",
      "4.49 0.0\n",
      "\n",
      "第 2 個 Attribute\n",
      "第一區間 [4.041 ~ max_num]\n",
      "第二區間 [3.592 ~ 4.041)\n",
      "第三區間 [3.143 ~ 3.592)\n",
      "第四區間 [2.694 ~ 3.143)\n",
      "第五區間 [2.245 ~ 2.694)\n",
      "第六區間 [1.796 ~ 2.245)\n",
      "第七區間 [1.347 ~ 1.796)\n",
      "第八區間 [0.898 ~ 1.347)\n",
      "第九區間 [0.449 ~ 0.898)\n",
      "第十區間 [min_num ~ 0.449)\n",
      "3.5 0.29\n",
      "\n",
      "第 3 個 Attribute\n",
      "第一區間 [3.179 ~ max_num]\n",
      "第二區間 [2.858 ~ 3.179)\n",
      "第三區間 [2.537 ~ 2.858)\n",
      "第四區間 [2.216 ~ 2.537)\n",
      "第五區間 [1.895 ~ 2.216)\n",
      "第六區間 [1.574 ~ 1.895)\n",
      "第七區間 [1.253 ~ 1.574)\n",
      "第八區間 [0.932 ~ 1.253)\n",
      "第九區間 [0.611 ~ 0.932)\n",
      "第十區間 [min_num ~ 0.611)\n",
      "75.41 69.81\n",
      "\n",
      "第 4 個 Attribute\n",
      "第一區間 [74.85 ~ max_num]\n",
      "第二區間 [74.29 ~ 74.85)\n",
      "第三區間 [73.73 ~ 74.29)\n",
      "第四區間 [73.17 ~ 73.73)\n",
      "第五區間 [72.61 ~ 73.17)\n",
      "第六區間 [72.05 ~ 72.61)\n",
      "第七區間 [71.49 ~ 72.05)\n",
      "第八區間 [70.93 ~ 71.49)\n",
      "第九區間 [70.37 ~ 70.93)\n",
      "第十區間 [min_num ~ 70.37)\n",
      "6.21 0.0\n",
      "\n",
      "第 5 個 Attribute\n",
      "第一區間 [5.589 ~ max_num]\n",
      "第二區間 [4.968 ~ 5.589)\n",
      "第三區間 [4.347 ~ 4.968)\n",
      "第四區間 [3.726 ~ 4.347)\n",
      "第五區間 [3.105 ~ 3.726)\n",
      "第六區間 [2.484 ~ 3.105)\n",
      "第七區間 [1.863 ~ 2.484)\n",
      "第八區間 [1.242 ~ 1.863)\n",
      "第九區間 [0.621 ~ 1.242)\n",
      "第十區間 [min_num ~ 0.621)\n",
      "16.19 5.43\n",
      "\n",
      "第 6 個 Attribute\n",
      "第一區間 [15.114 ~ max_num]\n",
      "第二區間 [14.038 ~ 15.114)\n",
      "第三區間 [12.962 ~ 14.038)\n",
      "第四區間 [11.886 ~ 12.962)\n",
      "第五區間 [10.81 ~ 11.886)\n",
      "第六區間 [9.734 ~ 10.81)\n",
      "第七區間 [8.658 ~ 9.734)\n",
      "第八區間 [7.582 ~ 8.658)\n",
      "第九區間 [6.506 ~ 7.582)\n",
      "第十區間 [min_num ~ 6.506)\n",
      "3.15 0.0\n",
      "\n",
      "第 7 個 Attribute\n",
      "第一區間 [2.835 ~ max_num]\n",
      "第二區間 [2.52 ~ 2.835)\n",
      "第三區間 [2.205 ~ 2.52)\n",
      "第四區間 [1.89 ~ 2.205)\n",
      "第五區間 [1.575 ~ 1.89)\n",
      "第六區間 [1.26 ~ 1.575)\n",
      "第七區間 [0.945 ~ 1.26)\n",
      "第八區間 [0.63 ~ 0.945)\n",
      "第九區間 [0.315 ~ 0.63)\n",
      "第十區間 [min_num ~ 0.315)\n",
      "0.51 0.0\n",
      "\n",
      "第 8 個 Attribute\n",
      "第一區間 [0.459 ~ max_num]\n",
      "第二區間 [0.408 ~ 0.459)\n",
      "第三區間 [0.357 ~ 0.408)\n",
      "第四區間 [0.306 ~ 0.357)\n",
      "第五區間 [0.255 ~ 0.306)\n",
      "第六區間 [0.204 ~ 0.255)\n",
      "第七區間 [0.153 ~ 0.204)\n",
      "第八區間 [0.102 ~ 0.153)\n",
      "第九區間 [0.051 ~ 0.102)\n",
      "第十區間 [min_num ~ 0.051)\n"
     ]
    }
   ],
   "source": [
    "Attributes_EWD = []\n",
    "for i in range(10):\n",
    "    \n",
    "    specific_col = Attributes[i]\n",
    "    \n",
    "    if i != 9:\n",
    "        number_of_intervals = 10\n",
    "        max_num_in_col = find_max(specific_col, DATA_COUNT)\n",
    "        min_num_in_col = find_min(specific_col, DATA_COUNT)\n",
    "        width = (max_num_in_col - min_num_in_col)/number_of_intervals\n",
    "        print(max_num_in_col, min_num_in_col)\n",
    "\n",
    "        # Decide 9 Split points, so that 10 intervals will form\n",
    "        split_point_1 = max_num_in_col - 1 * width\n",
    "        split_point_2 = max_num_in_col - 2 * width\n",
    "        split_point_3 = max_num_in_col - 3 * width\n",
    "        split_point_4 = max_num_in_col - 4 * width\n",
    "        split_point_5 = max_num_in_col - 5 * width\n",
    "        split_point_6 = max_num_in_col - 6 * width\n",
    "        split_point_7 = max_num_in_col - 7 * width\n",
    "        split_point_8 = max_num_in_col - 8 * width\n",
    "        split_point_9 = max_num_in_col - 9 * width\n",
    "\n",
    "        # transfer attributes into proper interval\n",
    "        discrete_attr = []\n",
    "        for j in range(DATA_COUNT):\n",
    "            discrete_attr.append(-100)\n",
    "\n",
    "        for j in range(DATA_COUNT):\n",
    "\n",
    "            num = specific_col[j]\n",
    "\n",
    "            if (num >= split_point_1): discrete_attr[j] = 0\n",
    "            elif (num >= split_point_2) and (num < split_point_1): discrete_attr[j] = 1\n",
    "            elif (num >= split_point_3) and (num < split_point_2): discrete_attr[j] = 2\n",
    "            elif (num >= split_point_4) and (num < split_point_3): discrete_attr[j] = 3\n",
    "            elif (num >= split_point_5) and (num < split_point_4): discrete_attr[j] = 4\n",
    "            elif (num >= split_point_6) and (num < split_point_5): discrete_attr[j] = 5\n",
    "            elif (num >= split_point_7) and (num < split_point_6): discrete_attr[j] = 6\n",
    "            elif (num >= split_point_8) and (num < split_point_7): discrete_attr[j] = 7\n",
    "            elif (num >= split_point_9) and (num < split_point_8): discrete_attr[j] = 8\n",
    "            elif (num  < split_point_9): discrete_attr[j] = 9\n",
    "                \n",
    "        Attributes_EWD.append(discrete_attr)\n",
    "        print(f\"\\n第 {str(i)} 個 Attribute\")\n",
    "        print(f\"第一區間 [{str(round(split_point_1,3))} ~ max_num]\")\n",
    "        print(f\"第二區間 [{str(round(split_point_2,3))} ~ {str(round(split_point_1,3))})\")\n",
    "        print(f\"第三區間 [{str(round(split_point_3,3))} ~ {str(round(split_point_2,3))})\")\n",
    "        print(f\"第四區間 [{str(round(split_point_4,3))} ~ {str(round(split_point_3,3))})\")\n",
    "        print(f\"第五區間 [{str(round(split_point_5,3))} ~ {str(round(split_point_4,3))})\")\n",
    "        print(f\"第六區間 [{str(round(split_point_6,3))} ~ {str(round(split_point_5,3))})\")\n",
    "        print(f\"第七區間 [{str(round(split_point_7,3))} ~ {str(round(split_point_6,3))})\")\n",
    "        print(f\"第八區間 [{str(round(split_point_8,3))} ~ {str(round(split_point_7,3))})\")\n",
    "        print(f\"第九區間 [{str(round(split_point_9,3))} ~ {str(round(split_point_8,3))})\")\n",
    "        print(f\"第十區間 [min_num ~ {str(round(split_point_9,3))})\")\n",
    "        \n",
    "    else:\n",
    "        Attributes_EWD.append(specific_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7fb723b",
   "metadata": {},
   "source": [
    "# Use Selective Naïve Bayes (w. Laplace estimate) to Forward Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9b91bfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chosen Subset: [0], Accuracy: 39.72 %\n",
      "Chosen Subset: [1], Accuracy: 40.654 %\n",
      "Chosen Subset: [2], Accuracy: 44.86 %\n",
      "Chosen Subset: [3], Accuracy: 50.467 %\n",
      "Chosen Subset: [4], Accuracy: 35.047 %\n",
      "Chosen Subset: [5], Accuracy: 44.393 %\n",
      "Chosen Subset: [6], Accuracy: 48.598 %\n",
      "Chosen Subset: [7], Accuracy: 46.729 %\n",
      "Chosen Subset: [8], Accuracy: 33.645 %\n",
      "Chosen Subset: [3, 0], Accuracy: 47.196 %\n",
      "Chosen Subset: [3, 1], Accuracy: 51.402 %\n",
      "Chosen Subset: [3, 2], Accuracy: 38.785 %\n",
      "Chosen Subset: [3, 4], Accuracy: 42.991 %\n",
      "Chosen Subset: [3, 5], Accuracy: 53.738 %\n",
      "Chosen Subset: [3, 6], Accuracy: 47.196 %\n",
      "Chosen Subset: [3, 7], Accuracy: 53.271 %\n",
      "Chosen Subset: [3, 8], Accuracy: 48.131 %\n",
      "Chosen Subset: [3, 5, 0], Accuracy: 53.271 %\n",
      "Chosen Subset: [3, 5, 1], Accuracy: 53.271 %\n",
      "Chosen Subset: [3, 5, 2], Accuracy: 54.206 %\n",
      "Chosen Subset: [3, 5, 4], Accuracy: 56.075 %\n",
      "Chosen Subset: [3, 5, 6], Accuracy: 52.336 %\n",
      "Chosen Subset: [3, 5, 7], Accuracy: 55.607 %\n",
      "Chosen Subset: [3, 5, 8], Accuracy: 52.336 %\n",
      "Chosen Subset: [3, 5, 4, 0], Accuracy: 54.673 %\n",
      "Chosen Subset: [3, 5, 4, 1], Accuracy: 57.009 %\n",
      "Chosen Subset: [3, 5, 4, 2], Accuracy: 55.14 %\n",
      "Chosen Subset: [3, 5, 4, 6], Accuracy: 51.869 %\n",
      "Chosen Subset: [3, 5, 4, 7], Accuracy: 57.944 %\n",
      "Chosen Subset: [3, 5, 4, 8], Accuracy: 54.206 %\n",
      "Chosen Subset: [3, 5, 4, 7, 0], Accuracy: 57.477 %\n",
      "Chosen Subset: [3, 5, 4, 7, 1], Accuracy: 57.477 %\n",
      "Chosen Subset: [3, 5, 4, 7, 2], Accuracy: 57.944 %\n",
      "Chosen Subset: [3, 5, 4, 7, 6], Accuracy: 54.673 %\n",
      "Chosen Subset: [3, 5, 4, 7, 8], Accuracy: 56.075 %\n",
      "Chosen Subset: [3, 5, 4, 7, 2, 0], Accuracy: 57.477 %\n",
      "Chosen Subset: [3, 5, 4, 7, 2, 1], Accuracy: 55.607 %\n",
      "Chosen Subset: [3, 5, 4, 7, 2, 6], Accuracy: 62.617 %\n",
      "Chosen Subset: [3, 5, 4, 7, 2, 8], Accuracy: 59.813 %\n",
      "Chosen Subset: [3, 5, 4, 7, 2, 6, 0], Accuracy: 59.813 %\n",
      "Chosen Subset: [3, 5, 4, 7, 2, 6, 1], Accuracy: 59.813 %\n",
      "Chosen Subset: [3, 5, 4, 7, 2, 6, 8], Accuracy: 62.15 %\n",
      "\n",
      "Finish. The best setting based on Selective Naive Bayes (with Laplace Estimate) is ...\n",
      "Chosen Subset: [3, 5, 4, 7, 2, 6], Accuracy: 62.617 %\n"
     ]
    }
   ],
   "source": [
    "must_chosen_subset = []\n",
    "possible_subset = [0,1,2,3,4,5,6,7,8]\n",
    "best_accuracy = 0\n",
    "\n",
    "while True:\n",
    "    \n",
    "    # 一個 accuracy 會對應到 一個 experiment 的 col\n",
    "    accuracy_list = []\n",
    "    exp_attr_list = []\n",
    "\n",
    "    # 進行同樣 attr 數目的搜索\n",
    "    for attr_num in possible_subset:\n",
    "\n",
    "        # 每次搜索過相同 level 的 subset 時，需要清空 chosen_subset\n",
    "        chosen_subset = [] # zero_subset 的概念\n",
    "\n",
    "        # 把那些 最棒的 attr 加進來\n",
    "        for best_attr_num in must_chosen_subset:\n",
    "            chosen_subset.append(best_attr_num)\n",
    "\n",
    "        # 這時候從 possible_subset 加一個候選的 attr 進到 chosen_subset\n",
    "        chosen_subset.append(attr_num)\n",
    "        exp_attr_list.append(attr_num)\n",
    "\n",
    "        # 計算 accuracy 並且將 accuracy 放入 accuracy_list\n",
    "        accuracy = selective_naive_bayes(Attributes_EWD, DATA_COUNT, chosen_subset, len(chosen_subset))\n",
    "        accuracy_list.append(accuracy)\n",
    "        #print(f\"Chosen S: {chosen_subset}; Goodness: {round(accuracy,3)}\")\n",
    "\n",
    "    # 找到 goodness 最大的 idx, 並透過 tmp_exp_col 找到 attr_num 和 goodness\n",
    "    idx = argmax(accuracy_list)\n",
    "    current_best_atrr = exp_attr_list[idx]\n",
    "    current_best_accuracy = accuracy_list[idx]\n",
    "\n",
    "    # 設定停止條件 \n",
    "    # (1) current_best_goodness 比 best_goodness 低 \n",
    "    # (2) possible_subset 用完了\n",
    "    if (current_best_accuracy < best_accuracy) or (len(possible_subset) < 2):\n",
    "        break;\n",
    "    else:\n",
    "        # 把當前最好的 attr 加進 must_chosen_subset 裡面\n",
    "        must_chosen_subset.append(current_best_atrr)\n",
    "        # 把當前最好的 attr 從 possible_subset 裡面取出\n",
    "        possible_subset.remove(current_best_atrr)\n",
    "        # 更新歷史上最好的 best_goodness\n",
    "        best_accuracy = current_best_accuracy\n",
    "\n",
    "print()\n",
    "print(f\"Finish. The best setting based on Selective Naive Bayes (with Laplace Estimate) is ...\")\n",
    "_ = selective_naive_bayes(Attributes_EWD, DATA_COUNT, must_chosen_subset, len(must_chosen_subset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e324a1",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "282f1497",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"../glass.txt\")\n",
    "DATA = f.readlines()\n",
    "DATA_COUNT = len(DATA)\n",
    "f.close()\n",
    "\n",
    "# 觀察到 DATA 目前為 string 形式，透過 split 拆解 string，並存入 DATA_NEW\n",
    "# 另外，想要將 col 和 row 的位置對調\n",
    "\n",
    "_attr, attr_0, attr_1, attr_2, attr_3, attr_4, attr_5, attr_6, attr_7, attr_8, attr_9 = [], [], [], [], [], [], [], [], [], [], []\n",
    "\n",
    "for row in DATA:\n",
    "\n",
    "    row_list = row.split(\",\")\n",
    "    \n",
    "    attr_0.append(float(row_list[1]))   \n",
    "    attr_1.append(float(row_list[2]))  \n",
    "    attr_2.append(float(row_list[3]))  \n",
    "    attr_3.append(float(row_list[4]))\n",
    "    attr_4.append(float(row_list[5]))\n",
    "    attr_5.append(float(row_list[6]))  \n",
    "    attr_6.append(float(row_list[7]))  \n",
    "    attr_7.append(float(row_list[8]))\n",
    "    attr_8.append(float(row_list[9]))\n",
    "    attr_9.append(row_list[10]) # 這個是 class\n",
    "    \n",
    "\n",
    "# 我只要透過 Attributes[0] 就能取得 DATA 第一個 Attribute 的所有值（預計有214個）\n",
    "Attributes = [attr_0, attr_1, attr_2, attr_3, attr_4, attr_5, attr_6, attr_7, attr_8, attr_9]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0933ee",
   "metadata": {},
   "source": [
    "# Equal-Frequency Discretization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88c27a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "Attributes_Sort = []\n",
    "\n",
    "for i in range(10):\n",
    "    if i < 9:\n",
    "        Attributes_Sort.append(sort_col(Attributes[i], DATA_COUNT))\n",
    "    else:\n",
    "        Attributes_Sort.append(Attributes[i])\n",
    "# 我只要透過 Attributes_Sort[0] 就能取得 DATA 第一個 Attribute 的所有值（預計有106個），而且還有由大排到小"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7126db83",
   "metadata": {},
   "source": [
    "# Read Data Again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9de3ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"../glass.txt\")\n",
    "DATA = f.readlines()\n",
    "DATA_COUNT = len(DATA)\n",
    "f.close()\n",
    "\n",
    "number_of_intervals = 10\n",
    "number_of_attr_in_interval = DATA_COUNT / number_of_intervals\n",
    "\n",
    "# 觀察到 DATA 目前為 string 形式，透過 split 拆解 string，並存入 DATA_NEW\n",
    "# 另外，想要將 col 和 row 的位置對調\n",
    "\n",
    "_attr, attr_0, attr_1, attr_2, attr_3, attr_4, attr_5, attr_6, attr_7, attr_8, attr_9 = [], [], [], [], [], [], [], [], [], [], []\n",
    "\n",
    "for row in DATA:\n",
    "\n",
    "    row_list = row.split(\",\")\n",
    "    \n",
    "    attr_0.append(float(row_list[1]))   \n",
    "    attr_1.append(float(row_list[2]))  \n",
    "    attr_2.append(float(row_list[3]))  \n",
    "    attr_3.append(float(row_list[4]))\n",
    "    attr_4.append(float(row_list[5]))\n",
    "    attr_5.append(float(row_list[6]))  \n",
    "    attr_6.append(float(row_list[7]))  \n",
    "    attr_7.append(float(row_list[8]))\n",
    "    attr_8.append(float(row_list[9]))\n",
    "    attr_9.append(row_list[10]) # 這個是 class\n",
    "    \n",
    "\n",
    "# 我只要透過 Attributes[0] 就能取得 DATA 第一個 Attribute 的所有值（預計有214個）\n",
    "Attributes = [attr_0, attr_1, attr_2, attr_3, attr_4, attr_5, attr_6, attr_7, attr_8, attr_9]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230d5858",
   "metadata": {},
   "source": [
    "# Equal-Frequency Discretization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "47a5fdbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "第 0 個 Attribute\n",
      "第一區間 [1.522 ~ max_num]\n",
      "第二區間 [1.52 ~ 1.522)\n",
      "第三區間 [1.519 ~ 1.52)\n",
      "第四區間 [1.518 ~ 1.519)\n",
      "第五區間 [1.518 ~ 1.518)\n",
      "第六區間 [1.517 ~ 1.518)\n",
      "第七區間 [1.517 ~ 1.517)\n",
      "第八區間 [1.516 ~ 1.517)\n",
      "第九區間 [1.516 ~ 1.516)\n",
      "第十區間 [min_num ~ 1.516)\n",
      "\n",
      "第 1 個 Attribute\n",
      "第一區間 [14.4 ~ max_num]\n",
      "第二區間 [14.03 ~ 14.4)\n",
      "第三區間 [13.71 ~ 14.03)\n",
      "第四區間 [13.46 ~ 13.71)\n",
      "第五區間 [13.31 ~ 13.46)\n",
      "第六區間 [13.19 ~ 13.31)\n",
      "第七區間 [13.0 ~ 13.19)\n",
      "第八區間 [12.86 ~ 13.0)\n",
      "第九區間 [12.71 ~ 12.86)\n",
      "第十區間 [min_num ~ 12.71)\n",
      "\n",
      "第 2 個 Attribute\n",
      "第一區間 [3.76 ~ max_num]\n",
      "第二區間 [3.64 ~ 3.76)\n",
      "第三區間 [3.58 ~ 3.64)\n",
      "第四區間 [3.54 ~ 3.58)\n",
      "第五區間 [3.48 ~ 3.54)\n",
      "第六區間 [3.4 ~ 3.48)\n",
      "第七區間 [2.85 ~ 3.4)\n",
      "第八區間 [1.35 ~ 2.85)\n",
      "第九區間 [0.0 ~ 1.35)\n",
      "第十區間 [min_num ~ 0.0)\n",
      "\n",
      "第 3 個 Attribute\n",
      "第一區間 [2.08 ~ max_num]\n",
      "第二區間 [1.76 ~ 2.08)\n",
      "第三區間 [1.56 ~ 1.76)\n",
      "第四區間 [1.49 ~ 1.56)\n",
      "第五區間 [1.37 ~ 1.49)\n",
      "第六區間 [1.3 ~ 1.37)\n",
      "第七區間 [1.23 ~ 1.3)\n",
      "第八區間 [1.16 ~ 1.23)\n",
      "第九區間 [0.89 ~ 1.16)\n",
      "第十區間 [min_num ~ 0.89)\n",
      "\n",
      "第 4 個 Attribute\n",
      "第一區間 [73.3 ~ max_num]\n",
      "第二區間 [73.15 ~ 73.3)\n",
      "第三區間 [73.03 ~ 73.15)\n",
      "第四區間 [72.95 ~ 73.03)\n",
      "第五區間 [72.81 ~ 72.95)\n",
      "第六區間 [72.67 ~ 72.81)\n",
      "第七區間 [72.44 ~ 72.67)\n",
      "第八區間 [72.18 ~ 72.44)\n",
      "第九區間 [71.79 ~ 72.18)\n",
      "第十區間 [min_num ~ 71.79)\n",
      "\n",
      "第 5 個 Attribute\n",
      "第一區間 [0.68 ~ max_num]\n",
      "第二區間 [0.62 ~ 0.68)\n",
      "第三區間 [0.6 ~ 0.62)\n",
      "第四區間 [0.57 ~ 0.6)\n",
      "第五區間 [0.56 ~ 0.57)\n",
      "第六區間 [0.51 ~ 0.56)\n",
      "第七區間 [0.23 ~ 0.51)\n",
      "第八區間 [0.09 ~ 0.23)\n",
      "第九區間 [0.0 ~ 0.09)\n",
      "第十區間 [min_num ~ 0.0)\n",
      "\n",
      "第 6 個 Attribute\n",
      "第一區間 [10.56 ~ max_num]\n",
      "第二區間 [9.57 ~ 10.56)\n",
      "第三區間 [9.03 ~ 9.57)\n",
      "第四區間 [8.79 ~ 9.03)\n",
      "第五區間 [8.61 ~ 8.79)\n",
      "第六區間 [8.5 ~ 8.61)\n",
      "第七區間 [8.38 ~ 8.5)\n",
      "第八區間 [8.17 ~ 8.38)\n",
      "第九區間 [7.99 ~ 8.17)\n",
      "第十區間 [min_num ~ 7.99)\n",
      "\n",
      "第 7 個 Attribute\n",
      "第一區間 [0.64 ~ max_num]\n",
      "第二區間 [0.0 ~ 0.64)\n",
      "第三區間 [0.0 ~ 0.0)\n",
      "第四區間 [0.0 ~ 0.0)\n",
      "第五區間 [0.0 ~ 0.0)\n",
      "第六區間 [0.0 ~ 0.0)\n",
      "第七區間 [0.0 ~ 0.0)\n",
      "第八區間 [0.0 ~ 0.0)\n",
      "第九區間 [0.0 ~ 0.0)\n",
      "第十區間 [min_num ~ 0.0)\n",
      "\n",
      "第 8 個 Attribute\n",
      "第一區間 [0.22 ~ max_num]\n",
      "第二區間 [0.14 ~ 0.22)\n",
      "第三區間 [0.07 ~ 0.14)\n",
      "第四區間 [0.0 ~ 0.07)\n",
      "第五區間 [0.0 ~ 0.0)\n",
      "第六區間 [0.0 ~ 0.0)\n",
      "第七區間 [0.0 ~ 0.0)\n",
      "第八區間 [0.0 ~ 0.0)\n",
      "第九區間 [0.0 ~ 0.0)\n",
      "第十區間 [min_num ~ 0.0)\n"
     ]
    }
   ],
   "source": [
    "Attributes_EFD = []\n",
    "\n",
    "for j in range(10):\n",
    "    specific_col_sort = Attributes_Sort[j]\n",
    "    specific_col = Attributes[j]\n",
    "        \n",
    "    if j != 9:\n",
    "\n",
    "        split_point_1 = specific_col_sort[1 * int(number_of_attr_in_interval)]\n",
    "        split_point_2 = specific_col_sort[2 * int(number_of_attr_in_interval)]\n",
    "        split_point_3 = specific_col_sort[3 * int(number_of_attr_in_interval)]\n",
    "        split_point_4 = specific_col_sort[4 * int(number_of_attr_in_interval)]\n",
    "        split_point_5 = specific_col_sort[5 * int(number_of_attr_in_interval)]\n",
    "        split_point_6 = specific_col_sort[6 * int(number_of_attr_in_interval)]\n",
    "        split_point_7 = specific_col_sort[7 * int(number_of_attr_in_interval)]\n",
    "        split_point_8 = specific_col_sort[8 * int(number_of_attr_in_interval)]\n",
    "        split_point_9 = specific_col_sort[9 * int(number_of_attr_in_interval)]\n",
    "\n",
    "        # transfer attributes into proper interval\n",
    "        discrete_attr = []\n",
    "        for i in range(DATA_COUNT):\n",
    "            discrete_attr.append(-100)\n",
    "\n",
    "        for i in range(DATA_COUNT):\n",
    "\n",
    "            num = specific_col[i]\n",
    "\n",
    "            if num >= split_point_1: discrete_attr[i] = 0\n",
    "            elif num >= split_point_2 and num < split_point_1: discrete_attr[i] = 1\n",
    "            elif num >= split_point_3 and num < split_point_2: discrete_attr[i] = 2\n",
    "            elif num >= split_point_4 and num < split_point_3: discrete_attr[i] = 3\n",
    "            elif num >= split_point_5 and num < split_point_4: discrete_attr[i] = 4\n",
    "            elif num >= split_point_6 and num < split_point_5: discrete_attr[i] = 5\n",
    "            elif num >= split_point_7 and num < split_point_6: discrete_attr[i] = 6\n",
    "            elif num >= split_point_8 and num < split_point_7: discrete_attr[i] = 7\n",
    "            elif num >= split_point_9 and num < split_point_8: discrete_attr[i] = 8\n",
    "            elif num < split_point_9: discrete_attr[i] = 9\n",
    "                \n",
    "        Attributes_EFD.append(discrete_attr)\n",
    "        print(f\"\\n第 {str(j)} 個 Attribute\")\n",
    "        print(f\"第一區間 [{str(round(split_point_1,3))} ~ max_num]\")\n",
    "        print(f\"第二區間 [{str(round(split_point_2,3))} ~ {str(round(split_point_1,3))})\")\n",
    "        print(f\"第三區間 [{str(round(split_point_3,3))} ~ {str(round(split_point_2,3))})\")\n",
    "        print(f\"第四區間 [{str(round(split_point_4,3))} ~ {str(round(split_point_3,3))})\")\n",
    "        print(f\"第五區間 [{str(round(split_point_5,3))} ~ {str(round(split_point_4,3))})\")\n",
    "        print(f\"第六區間 [{str(round(split_point_6,3))} ~ {str(round(split_point_5,3))})\")\n",
    "        print(f\"第七區間 [{str(round(split_point_7,3))} ~ {str(round(split_point_6,3))})\")\n",
    "        print(f\"第八區間 [{str(round(split_point_8,3))} ~ {str(round(split_point_7,3))})\")\n",
    "        print(f\"第九區間 [{str(round(split_point_9,3))} ~ {str(round(split_point_8,3))})\")\n",
    "        print(f\"第十區間 [min_num ~ {str(round(split_point_9,3))})\")\n",
    "    else:\n",
    "        Attributes_EFD.append(specific_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9414b14",
   "metadata": {},
   "source": [
    "# Use Selective Naïve Bayes (w. Laplace estimate) to Forward Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "239faa4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chosen Subset: [0], Accuracy: 52.804 %\n",
      "Chosen Subset: [1], Accuracy: 45.327 %\n",
      "Chosen Subset: [2], Accuracy: 38.318 %\n",
      "Chosen Subset: [3], Accuracy: 57.944 %\n",
      "Chosen Subset: [4], Accuracy: 43.458 %\n",
      "Chosen Subset: [5], Accuracy: 43.458 %\n",
      "Chosen Subset: [6], Accuracy: 49.065 %\n",
      "Chosen Subset: [7], Accuracy: 44.393 %\n",
      "Chosen Subset: [8], Accuracy: 36.916 %\n",
      "Chosen Subset: [3, 0], Accuracy: 58.879 %\n",
      "Chosen Subset: [3, 1], Accuracy: 55.14 %\n",
      "Chosen Subset: [3, 2], Accuracy: 57.944 %\n",
      "Chosen Subset: [3, 4], Accuracy: 54.673 %\n",
      "Chosen Subset: [3, 5], Accuracy: 52.336 %\n",
      "Chosen Subset: [3, 6], Accuracy: 57.477 %\n",
      "Chosen Subset: [3, 7], Accuracy: 57.009 %\n",
      "Chosen Subset: [3, 8], Accuracy: 57.009 %\n",
      "Chosen Subset: [3, 0, 1], Accuracy: 60.28 %\n",
      "Chosen Subset: [3, 0, 2], Accuracy: 62.617 %\n",
      "Chosen Subset: [3, 0, 4], Accuracy: 57.944 %\n",
      "Chosen Subset: [3, 0, 5], Accuracy: 60.748 %\n",
      "Chosen Subset: [3, 0, 6], Accuracy: 62.617 %\n",
      "Chosen Subset: [3, 0, 7], Accuracy: 60.748 %\n",
      "Chosen Subset: [3, 0, 8], Accuracy: 61.215 %\n",
      "Chosen Subset: [3, 0, 2, 1], Accuracy: 67.29 %\n",
      "Chosen Subset: [3, 0, 2, 4], Accuracy: 62.617 %\n",
      "Chosen Subset: [3, 0, 2, 5], Accuracy: 64.953 %\n",
      "Chosen Subset: [3, 0, 2, 6], Accuracy: 65.888 %\n",
      "Chosen Subset: [3, 0, 2, 7], Accuracy: 65.888 %\n",
      "Chosen Subset: [3, 0, 2, 8], Accuracy: 64.953 %\n",
      "Chosen Subset: [3, 0, 2, 1, 4], Accuracy: 64.486 %\n",
      "Chosen Subset: [3, 0, 2, 1, 5], Accuracy: 63.084 %\n",
      "Chosen Subset: [3, 0, 2, 1, 6], Accuracy: 67.29 %\n",
      "Chosen Subset: [3, 0, 2, 1, 7], Accuracy: 69.626 %\n",
      "Chosen Subset: [3, 0, 2, 1, 8], Accuracy: 65.888 %\n",
      "Chosen Subset: [3, 0, 2, 1, 7, 4], Accuracy: 67.29 %\n",
      "Chosen Subset: [3, 0, 2, 1, 7, 5], Accuracy: 67.29 %\n",
      "Chosen Subset: [3, 0, 2, 1, 7, 6], Accuracy: 68.692 %\n",
      "Chosen Subset: [3, 0, 2, 1, 7, 8], Accuracy: 68.692 %\n",
      "\n",
      "Finish. The best setting based on Selective Naive Bayes (with Laplace Estimate) is ...\n",
      "Chosen Subset: [3, 0, 2, 1, 7], Accuracy: 69.626 %\n"
     ]
    }
   ],
   "source": [
    "must_chosen_subset = []\n",
    "possible_subset = [0,1,2,3,4,5,6,7,8]\n",
    "best_accuracy = 0\n",
    "\n",
    "while True:\n",
    "    \n",
    "    # 一個 accuracy 會對應到 一個 experiment 的 col\n",
    "    accuracy_list = []\n",
    "    exp_attr_list = []\n",
    "\n",
    "    # 進行同樣 attr 數目的搜索\n",
    "    for attr_num in possible_subset:\n",
    "\n",
    "        # 每次搜索過相同 level 的 subset 時，需要清空 chosen_subset\n",
    "        chosen_subset = [] # zero_subset 的概念\n",
    "\n",
    "        # 把那些 最棒的 attr 加進來\n",
    "        for best_attr_num in must_chosen_subset:\n",
    "            chosen_subset.append(best_attr_num)\n",
    "\n",
    "        # 這時候從 possible_subset 加一個候選的 attr 進到 chosen_subset\n",
    "        chosen_subset.append(attr_num)\n",
    "        exp_attr_list.append(attr_num)\n",
    "\n",
    "        # 計算 accuracy 並且將 accuracy 放入 accuracy_list\n",
    "        accuracy = selective_naive_bayes(Attributes_EFD, DATA_COUNT, chosen_subset, len(chosen_subset))\n",
    "        accuracy_list.append(accuracy)\n",
    "        #print(f\"Chosen S: {chosen_subset}; Goodness: {round(accuracy,3)}\")\n",
    "\n",
    "    # 找到 goodness 最大的 idx, 並透過 tmp_exp_col 找到 attr_num 和 goodness\n",
    "    idx = argmax(accuracy_list)\n",
    "    current_best_atrr = exp_attr_list[idx]\n",
    "    current_best_accuracy = accuracy_list[idx]\n",
    "\n",
    "    # 設定停止條件 \n",
    "    # (1) current_best_goodness 比 best_goodness 低 \n",
    "    # (2) possible_subset 用完了\n",
    "    if (current_best_accuracy < best_accuracy) or (len(possible_subset) < 2):\n",
    "        break;\n",
    "    else:\n",
    "        # 把當前最好的 attr 加進 must_chosen_subset 裡面\n",
    "        must_chosen_subset.append(current_best_atrr)\n",
    "        # 把當前最好的 attr 從 possible_subset 裡面取出\n",
    "        possible_subset.remove(current_best_atrr)\n",
    "        # 更新歷史上最好的 best_goodness\n",
    "        best_accuracy = current_best_accuracy\n",
    "\n",
    "print()\n",
    "print(f\"Finish. The best setting based on Selective Naive Bayes (with Laplace Estimate) is ...\")\n",
    "_ = selective_naive_bayes(Attributes_EFD, DATA_COUNT, must_chosen_subset, len(must_chosen_subset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b87f750b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entropy-based Discretization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1452e4c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "len(np.unique(Attributes_EWD[9][0:212]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
